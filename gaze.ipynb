{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5710, 0.9573, 0.8388,  ..., 0.4309, 0.6644, 0.3738],\n",
      "         [0.4550, 0.9207, 0.3412,  ..., 0.0932, 0.2880, 0.1926],\n",
      "         [0.7916, 0.8939, 0.8359,  ..., 0.6462, 0.1381, 0.6904],\n",
      "         ...,\n",
      "         [0.0104, 0.5017, 0.1842,  ..., 0.5362, 0.9441, 0.2077],\n",
      "         [0.5548, 0.9118, 0.8449,  ..., 0.0899, 0.1121, 0.2897],\n",
      "         [0.7365, 0.4915, 0.4410,  ..., 0.0795, 0.9189, 0.3403]],\n",
      "\n",
      "        [[0.5119, 0.1292, 0.6125,  ..., 0.5156, 0.3652, 0.9493],\n",
      "         [0.9338, 0.7321, 0.2504,  ..., 0.1962, 0.4210, 0.7808],\n",
      "         [0.9430, 0.5609, 0.2115,  ..., 0.3353, 0.9994, 0.5822],\n",
      "         ...,\n",
      "         [0.2121, 0.2898, 0.7662,  ..., 0.5397, 0.2893, 0.7222],\n",
      "         [0.6827, 0.8154, 0.9964,  ..., 0.4438, 0.2510, 0.8919],\n",
      "         [0.1765, 0.3628, 0.9784,  ..., 0.1422, 0.8220, 0.3777]],\n",
      "\n",
      "        [[0.6562, 0.0836, 0.2420,  ..., 0.9649, 0.9346, 0.7702],\n",
      "         [0.3285, 0.0924, 0.1178,  ..., 0.1298, 0.7029, 0.4461],\n",
      "         [0.8435, 0.2155, 0.7781,  ..., 0.3284, 0.9975, 0.2953],\n",
      "         ...,\n",
      "         [0.8977, 0.6080, 0.8973,  ..., 0.8986, 0.2496, 0.6602],\n",
      "         [0.7738, 0.8164, 0.4876,  ..., 0.2804, 0.8498, 0.5826],\n",
      "         [0.9143, 0.6998, 0.7364,  ..., 0.5688, 0.3759, 0.4483]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9077, 0.9248, 0.5407,  ..., 0.2123, 0.2636, 0.0584],\n",
      "         [0.0105, 0.4230, 0.6811,  ..., 0.1594, 0.9643, 0.5759],\n",
      "         [0.3205, 0.4272, 0.8567,  ..., 0.4696, 0.4595, 0.8546],\n",
      "         ...,\n",
      "         [0.0954, 0.2292, 0.9382,  ..., 0.3039, 0.3200, 0.0935],\n",
      "         [0.3141, 0.4354, 0.2848,  ..., 0.2306, 0.5372, 0.4479],\n",
      "         [0.0423, 0.2875, 0.3589,  ..., 0.8339, 0.1823, 0.9015]],\n",
      "\n",
      "        [[0.9408, 0.1842, 0.7632,  ..., 0.0579, 0.9685, 0.4517],\n",
      "         [0.4484, 0.1588, 0.6702,  ..., 0.1876, 0.6046, 0.8317],\n",
      "         [0.8193, 0.9229, 0.6626,  ..., 0.3863, 0.1538, 0.2045],\n",
      "         ...,\n",
      "         [0.9829, 0.2113, 0.0784,  ..., 0.7292, 0.8639, 0.6146],\n",
      "         [0.8451, 0.8391, 0.5837,  ..., 0.3395, 0.2747, 0.7959],\n",
      "         [0.1110, 0.3790, 0.0608,  ..., 0.4756, 0.0099, 0.9902]],\n",
      "\n",
      "        [[0.8302, 0.2119, 0.8219,  ..., 0.7396, 0.0535, 0.5265],\n",
      "         [0.0119, 0.3496, 0.3367,  ..., 0.7238, 0.5678, 0.1041],\n",
      "         [0.4086, 0.4284, 0.7426,  ..., 0.9752, 0.5476, 0.5042],\n",
      "         ...,\n",
      "         [0.0500, 0.7454, 0.2319,  ..., 0.5368, 0.0758, 0.3623],\n",
      "         [0.1364, 0.5961, 0.8774,  ..., 0.9715, 0.4872, 0.5962],\n",
      "         [0.1855, 0.4177, 0.9306,  ..., 0.3678, 0.2819, 0.5794]]])\n",
      "tensor([[[0.2537, 0.3039, 0.6258,  ..., 0.1779, 0.6480, 0.5900],\n",
      "         [0.6435, 0.4242, 0.2424,  ..., 0.4732, 0.4551, 0.6027],\n",
      "         [0.5539, 0.1854, 0.9083,  ..., 0.6259, 0.1806, 0.1439],\n",
      "         ...,\n",
      "         [0.0620, 0.8705, 0.9406,  ..., 0.6527, 0.9442, 0.1902],\n",
      "         [0.4235, 0.8873, 0.5810,  ..., 0.5406, 0.8769, 0.4172],\n",
      "         [0.8804, 0.2839, 0.7006,  ..., 0.5680, 0.6632, 0.1639]],\n",
      "\n",
      "        [[0.7535, 0.5040, 0.0680,  ..., 0.8841, 0.5332, 0.4690],\n",
      "         [0.1157, 0.9299, 0.8979,  ..., 0.7438, 0.6352, 0.9505],\n",
      "         [0.2132, 0.0842, 0.4343,  ..., 0.9461, 0.1503, 0.5823],\n",
      "         ...,\n",
      "         [0.0775, 0.1509, 0.0460,  ..., 0.8505, 0.5586, 0.8517],\n",
      "         [0.8829, 0.7207, 0.4176,  ..., 0.5806, 0.5374, 0.3961],\n",
      "         [0.4698, 0.8478, 0.2368,  ..., 0.2103, 0.0199, 0.7129]],\n",
      "\n",
      "        [[0.7041, 0.4032, 0.8004,  ..., 0.0374, 0.3722, 0.3858],\n",
      "         [0.8084, 0.0924, 0.1271,  ..., 0.7846, 0.0191, 0.2902],\n",
      "         [0.6841, 0.4435, 0.9883,  ..., 0.3691, 0.0767, 0.9681],\n",
      "         ...,\n",
      "         [0.2459, 0.7251, 0.9000,  ..., 0.5740, 0.0528, 0.9487],\n",
      "         [0.7622, 0.2525, 0.3770,  ..., 0.0822, 0.2913, 0.5335],\n",
      "         [0.2411, 0.5131, 0.6125,  ..., 0.5389, 0.1256, 0.3103]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.6528, 0.7505, 0.5299,  ..., 0.7578, 0.3345, 0.1135],\n",
      "         [0.1829, 0.4590, 0.5199,  ..., 0.8053, 0.1751, 0.8974],\n",
      "         [0.8176, 0.2551, 0.2527,  ..., 0.1797, 0.2271, 0.9733],\n",
      "         ...,\n",
      "         [0.2627, 0.5778, 0.5425,  ..., 0.4675, 0.8769, 0.4765],\n",
      "         [0.2797, 0.4012, 0.3238,  ..., 0.0896, 0.8202, 0.8590],\n",
      "         [0.5439, 0.0952, 0.2366,  ..., 0.0845, 0.4745, 0.7860]],\n",
      "\n",
      "        [[0.0233, 0.1857, 0.4829,  ..., 0.9102, 0.8332, 0.0684],\n",
      "         [0.3234, 0.5379, 0.4113,  ..., 0.6592, 0.9931, 0.9955],\n",
      "         [0.6507, 0.5272, 0.1932,  ..., 0.5871, 0.4450, 0.6007],\n",
      "         ...,\n",
      "         [0.7951, 0.2790, 0.4660,  ..., 0.0812, 0.6081, 0.2433],\n",
      "         [0.4041, 0.0214, 0.0649,  ..., 0.9465, 0.9617, 0.2575],\n",
      "         [0.9714, 0.0626, 0.2430,  ..., 0.4870, 0.3437, 0.6241]],\n",
      "\n",
      "        [[0.8065, 0.0637, 0.8070,  ..., 0.7068, 0.2693, 0.3265],\n",
      "         [0.5907, 0.1264, 0.6951,  ..., 0.9875, 0.3168, 0.3884],\n",
      "         [0.2598, 0.7142, 0.7080,  ..., 0.5175, 0.8474, 0.7277],\n",
      "         ...,\n",
      "         [0.3783, 0.1298, 0.7747,  ..., 0.8761, 0.6687, 0.5749],\n",
      "         [0.1795, 0.5536, 0.6489,  ..., 0.6662, 0.8714, 0.9324],\n",
      "         [0.1661, 0.9107, 0.1694,  ..., 0.4478, 0.9681, 0.5604]]])\n",
      "tensor([[[0.5778, 0.5026, 0.5012,  ..., 0.1053, 0.9654, 0.5283],\n",
      "         [0.1398, 0.1748, 0.7581,  ..., 0.9902, 0.8585, 0.9064],\n",
      "         [0.3216, 0.6213, 0.5006,  ..., 0.2370, 0.1078, 0.4074],\n",
      "         ...,\n",
      "         [0.9749, 0.6066, 0.3336,  ..., 0.6912, 0.8957, 0.1152],\n",
      "         [0.3390, 0.8611, 0.1666,  ..., 0.8829, 0.1001, 0.8152],\n",
      "         [0.8121, 0.2205, 0.8410,  ..., 0.5803, 0.4911, 0.7079]],\n",
      "\n",
      "        [[0.6358, 0.1896, 0.5174,  ..., 0.5062, 0.0496, 0.0463],\n",
      "         [0.4838, 0.0868, 0.0195,  ..., 0.3898, 0.5126, 0.6348],\n",
      "         [0.8379, 0.7533, 0.0274,  ..., 0.5170, 0.3322, 0.7325],\n",
      "         ...,\n",
      "         [0.2222, 0.6688, 0.1226,  ..., 0.4753, 0.4000, 0.4324],\n",
      "         [0.6900, 0.5529, 0.0373,  ..., 0.8207, 0.6238, 0.9124],\n",
      "         [0.9840, 0.7525, 0.3045,  ..., 0.3171, 0.8073, 0.0483]],\n",
      "\n",
      "        [[0.3775, 0.4031, 0.8934,  ..., 0.0985, 0.9954, 0.9841],\n",
      "         [0.3722, 0.0606, 0.1916,  ..., 0.7174, 0.5406, 0.8603],\n",
      "         [0.2829, 0.5225, 0.3643,  ..., 0.4635, 0.4848, 0.5136],\n",
      "         ...,\n",
      "         [0.2648, 0.3867, 0.7235,  ..., 0.2075, 0.9268, 0.9462],\n",
      "         [0.6251, 0.3020, 0.2889,  ..., 0.9815, 0.7236, 0.7729],\n",
      "         [0.3982, 0.3025, 0.7541,  ..., 0.5894, 0.0328, 0.3083]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2237, 0.7499, 0.0635,  ..., 0.5835, 0.8504, 0.4891],\n",
      "         [0.9002, 0.4576, 0.4069,  ..., 0.6970, 0.2538, 0.9872],\n",
      "         [0.5590, 0.2569, 0.0796,  ..., 0.7111, 0.4358, 0.2132],\n",
      "         ...,\n",
      "         [0.0124, 0.1869, 0.1373,  ..., 0.8079, 0.7160, 0.0470],\n",
      "         [0.5630, 0.5045, 0.9253,  ..., 0.9168, 0.0091, 0.2268],\n",
      "         [0.8403, 0.1152, 0.0431,  ..., 0.3639, 0.3255, 0.3334]],\n",
      "\n",
      "        [[0.6635, 0.1288, 0.8505,  ..., 0.7616, 0.6750, 0.6126],\n",
      "         [0.9260, 0.4415, 0.7586,  ..., 0.4231, 0.4211, 0.9976],\n",
      "         [0.2723, 0.5295, 0.6678,  ..., 0.7574, 0.5773, 0.4669],\n",
      "         ...,\n",
      "         [0.4049, 0.2197, 0.0588,  ..., 0.8759, 0.1470, 0.9997],\n",
      "         [0.5441, 0.8798, 0.9655,  ..., 0.7528, 0.0528, 1.0000],\n",
      "         [0.0469, 0.0188, 0.5933,  ..., 0.8978, 0.8292, 0.2718]],\n",
      "\n",
      "        [[0.1215, 0.2995, 0.9569,  ..., 0.5309, 0.2078, 0.0747],\n",
      "         [0.2402, 0.2947, 0.3971,  ..., 0.7022, 0.2707, 0.7436],\n",
      "         [0.1586, 0.1578, 0.6287,  ..., 0.6979, 0.3710, 0.4213],\n",
      "         ...,\n",
      "         [0.9215, 0.4309, 0.7787,  ..., 0.9174, 0.2988, 0.2054],\n",
      "         [0.4212, 0.3937, 0.5948,  ..., 0.1675, 0.7181, 0.4902],\n",
      "         [0.6374, 0.0852, 0.6590,  ..., 0.4557, 0.1117, 0.4095]]])\n",
      "TinyModel(\n",
      "  (gn): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lingn\\AppData\\Local\\Temp\\ipykernel_11480\\3743870404.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  concate = torch.cat((torch.tensor(left_eye), torch.tensor(right_eye), torch.tensor(face)), 1)  # dim = 0 or 1?  only channel dim changes?\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 128 but got size 32 for tensor number 2 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m model \u001b[38;5;241m=\u001b[39m TinyModel()\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[1;32m---> 36\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLeye\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mReye\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFaceData\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# currently the face Data is not matched with eyes, should be matched in the future, how to match? linear padding or other methods? would it affect the performance if change the size of facedata\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput:\u001b[39m\u001b[38;5;124m\"\u001b[39m,output\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32me:\\anaconda3New\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\anaconda3New\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[3], line 29\u001b[0m, in \u001b[0;36mTinyModel.forward\u001b[1;34m(self, left_eye, right_eye, face)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, left_eye, right_eye, face):\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# layer2\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     concate \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_eye\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright_eye\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# dim = 0 or 1?  only channel dim changes?\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgn(concate)\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 128 but got size 32 for tensor number 2 in the list."
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "\n",
    "# input of layer 2\n",
    "Leye = torch.rand(128, 8, 8)\n",
    "print(Leye)\n",
    "\n",
    "Reye = torch.rand(128, 8, 8)\n",
    "print(Reye)\n",
    "\n",
    "FaceData = torch.rand(32, 8, 8)\n",
    "print(FaceData)\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "        # layer 1: feature extraction (to be implemented)\n",
    "        \n",
    "\n",
    "        # layer 2: feature fusion: concate + group  normalization\n",
    "        # self.concate = torch.cat((x, x, x), 0) // not needed here, only in forward\n",
    "        self.gn = torch.nn.GroupNorm(3, 6)     # Separate 6 channels into 3 groups, how to define a appropriate number of groups & channels?\n",
    "\n",
    "        # layer 3:.......................\n",
    "    \n",
    "    def forward(self, left_eye, right_eye, face):\n",
    "\n",
    "        # layer2\n",
    "        concate = torch.cat((torch.tensor(left_eye), torch.tensor(right_eye), torch.tensor(face)), 1)  # dim = 0 or 1?  only channel dim changes?\n",
    "        out = self.gn(concate)\n",
    "        return out\n",
    "\n",
    "model = TinyModel()\n",
    "print(model)\n",
    "\n",
    "output = model(Leye, Reye, FaceData)  # currently the face Data is not matched with eyes, should be matched in the future, how to match? linear padding or other methods? would it affect the performance if change the size of facedata\n",
    "print(\"output:\",output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
